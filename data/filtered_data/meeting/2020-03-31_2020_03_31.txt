Subcommittee Update: Grant Review Process – PPT handout
Content
• Session Goals/Agenda
• Grant Subcommittee
• Year One
• Application Process Considerations
• Timing of Applications
• Ease of Application Process
• Types of Eligible Funding Requests
• Size of Grants
• Scoring
• Review and Decision Process
• Eligibility
• Estimated Review Workload
• Who Reviews
Session Goals (slide 8)
Primary goals today are:
• Update on subcommittee work and anticipated timeframe moving forward
• Application Review Process – provide update on current thinking and solicit feedback and
discussion in target areas. Note that we will not be asking for any decisions today. Also, we
won’t be talking about the RFP, outreach and TA to potential grantees, or portfolio balancing.
Focus today is the application review process.
Grant Subcommittee (slide 10)
• Members include Faith, Megan, Ranfis, and Robin. Staffed by Cady and Janet.
• Background research to learn from other funders has included online research in addition to
interviews with grantmaking organizations. These funders include government and private
foundations, some with an equity focus and some with topical focus that fits with PCEF buckets.
• Grounded in:
an intention to have clarity and ease for applicants and reviewers
o
adherence to our draft guiding principles
o
PCEF legislative requirements and guidance
o
input from panel presentations and public comment.
o
Year One (slide 11)
• The first year will be different than other years due to:
Less money to distribute
o
Significant time is being spent to building the program while also launching and running
o
the program; fairly aggressive timeframe for what needs to be done; current staffing
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 1
levels are not 100 percent. Less time means some things that can’t be done (e.g. LOI,
multiple solicitations, etc.)
A lot of uncertainty and learning, even more given COVID situation.
o
Application Process Considerations (slide 12)
• Timing of Applications
• Ease of Application Process
• Eligibility Criteria
• Components of Review Process
Timing of Applications (slide 13)
• Year One - One round of funding.
• Future Years - Could be more than one round of funding.
Two cycles for all buckets – e.g., spring and fall.
o
Two cycles for certain buckets – timed to meet the needs of specific populations such as
o
farmers or schools.
Mini grants could be accepted each cycle, and perhaps even more frequently.
o
• Considerations
Separate funding rounds for distinct technologies may ease administrative burden in
o
review process.
Potential applicants have articulated a desire to see more than one funding cycle per
o
year and certain sectors have indicated times of year that are a barrier.
Need to limit funding cycles per year to allow staff time for other work.
o
• Recommendation: Year 1, one solicitation.
• Recommendation: Staff to conduct additional research on ideal/preferred funding cycles for
future years and bring back to subcommittee/committee (after round one).
Ease of Application Process (slide 14)
Goal is to create a process that is accessible and low burden to applicants with requirements that are
appropriate to grant size and type. Features discussed include:
• Timely communication (e.g. ample notice of RFP due date, Q&A sessions during application
period, applicant listserve email notice).
• Clarity and transparency (e.g., use plain language to describe what we want, how we will review
proposals, provide reviewer scoresheets in RFP).
• Effort appropriate to request (e.g. word limits that fit the relative importance of the item as well
as the size of the funding request, easier process for smaller grants, critical lens to the value of
information requested/don’t ask for information we don’t really need).
• Consistent definitions (e.g., definition of low income used by other agencies/funders; we will
create a glossary).
• Inclusive processes (e.g., some organizations are more equipped to write grants than others,
support for people who do not speak English or speak English as a second language, offer online
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 2
portal that meets accessibility standards and allow alternative means to submit an application
such as hard copies rather than electronic).
• Capacity building (e.g., provide examples to applicants, technical assistance).
• Continuous learning (seek anonymous feedback on the application process).
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback: Anything to add, delete, suggest?
Types of Eligible Funding Requests (slide 15)
Enabling legislation describes categories and types of projects. The committee can provide additional
parameters on eligibility requirements. Funding requests that the committee may want to consider
include the following:
• Capital projects – Examples of capital projects include, but are not limited to, weatherization,
solar installation, EV charging station, green infrastructure installation.
• Programming – Examples of programming projects include, but are not limited to, workforce
training, community outreach effort.
• Planning Grants - Examples of planning projects include, but are not limited to, identifying
priority parcels for green infrastructure investment, building partnerships to launch new
initiative, hiring a contractor to do energy assessments of building(s), etc. Note that certain
activities might be an appropriate component in multiple types of grants (planning/
programming/capital projects).
• Capacity building/technical assistance - Examples of capacity building and technical assistance
include, but are not limited to, implementing a financial management system, enhancing DEI
capacity of board and staff.
• Operating support – Several presenters have indicated a desire for funding of general operating
support; many of their examples of operating support actually describe specific activities such as
capacity building or planning grants. PCEF funds can 1) allow for overhead on grants which
covers some elements of operating support and 2) provide capacity building and planning
grants. Grants for general operating support that do not have a deliverable such as capacity
building or planning are not recommended.
• Innovation. Code language: “This category is intended to provide the Committee with flexibility
to fund a project that does not directly fall under one of the other categories, but which
provides an opportunity to further the goals of this Chapter.” Innovation requires a fair degree
of flexibility and responsiveness. Today we do not need to decide the mechanics of this; just
agreeing that per the legislation, this is a bucket that is eligible.
• Potential parameters by size of request - Are there any floors or ceilings for grant requests (e.g., no
less than, no more than $x) and, if so, are caps based on total dollars, percent of organizational
budget, or something else. If there are caps, what is the rationale (e.g., amount of time it takes to
review applications, not be the sole or majority funder of an organization)?
• Defining what is not allowed and any other restrictions– e.g., investments in individual businesses,
not reselling equipment purchased with grant funds. Will need to define this (but not this evening).
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 3
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback: Anything to add, delete, suggest? Feedback on parameters?
Size of Grants (slide 16)
• There will be a variety of sizes of grants awarded. There is 1) a wide range of capacity to
administer grants in the non-profit sector and 2) there is a variety of sizes and types of projects
that applicants will be interested in pursuing. PCEF legislation clearly articulates support for
capacity building in addition to supporting projects for existing and emerging organizations.
Grants of different sizes should be awarded in order to meet the needs of different types of
organizations and projects, and the application process and requirements for those different
sizes of grants should differ appropriately.
• Recommendation: PCEF should a) offer mini-grants, small grants, and large grants that meet the
varying capacity and needs of applicants and b) the application, monitoring, and reporting
requirements should be tailored appropriately to size of grant. The details of what those
differences would be is still being explored but will fit within the basic review and decision
process framework described below.
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback: Anything to add, delete, suggest?
Scoring (slide 17)
Items being considered include:
• Scale - Define criteria and provide a scoring option that allows different types of measures to be
defined in the same terms – e.g., each is rated on a scale of 1 to 5 or 0 to 100. Subcommittee is
working on draft criteria for each funding bucket for future work session with full committee.
• Minimum Scores– Are there minimum scores for some or all of the criteria or categories, or in
aggregate, below which an application would not be considered further?
• Ranking - Projects may be ranked within funding “buckets” based on scores.
• Inter-rater reliability – This refers to the ways to account for people who score differently. One
way that accounts for this is to have multiple people review an application and average scores
or compare scores and explore where there are significant areas of difference. Another option is
to use z scores which normalizes scores to account for individual scoring tendencies (e.g., some
people may generally be high scorers or low scorers).
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback – response to minimum scoring.
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 4
Review Process (slide 18)
Key steps in the Review and Decision process:
• Letter of Intent/Interest/Inquiry (LOI) or Pre-proposal – define what this is and potential
pros/cons. Note that it won’t be utilized this year due to timing; can come back to at future
meetings.
• Eligibility Screening. First step is to ensure applicant meets all eligibility criteria. Staff will
perform the eligibility screening function. Eligibility criteria are described below.
• Substantive Review. The application and its associated substantive review will look different
depending upon size and type of (e.g., all capital grants, all grants over a certain dollar
threshold. We will need to determine how to set those thresholds (e.g., industry standard,
concerns about large losses/minimize risk). Elements of the substantive review include:
Initial Threshold Review – If there are a large number of applications would we utilize an
o
Initial Threshold Review by staff before the Scoring Panel Review (next step below)? This
is done in order to reduce the number of applications that receive a more substantive
review when the number of applications exceeds available resources (i.e., more to
review than panel can handle). This type of review is not uncommon, organizations like
Social Justice Fund use a staff screening review to reduce the number of applications
scored by a full panel to a manageable size.
The if/then scenario being suggested has the Committee task staff with
performing an Initial Threshold Review only if the number of applications received is too
large to allow for committee participation on scoring panels for all of the applications
received. The Initial Threshold Review would be conducted by a minimum of two staff
per application.
A subcommittee could be formed to conduct random checks to confirm that
scoring is yielding outcomes consistent with what would be achieved with a broader
panel review. The Committee would also receive a report detailing the characteristics of
all applications and those that passed the threshold review as another check on bias in
this stage. In circumstances where a threshold review is performed and the number of
applications is still too large, a cutoff could be established to reduce the number that
advance to panel scoring (e.g., highest scoring applications up to twice the level of
funding available).
Scoring Panel Review – Scoring of proposal by teams. Each scoring panel (team) could
o
include staff, Committee members, City subject matter experts (SMEs), and/or
community volunteers. The size of the review panel must balance operational logistics
with the goal of reducing bias. Anticipate teams will include three to six people
reviewing the same proposal. Panel can meet to compare scores and explore any
significant differences. Clarifying questions could be permitted, with the response used
to inform scores.
Technical Review – Some types and sizes of projects will need a technical review which
o
considers things like feasibility and best practice. For example, whole building retrofits
would be subject to technical review by building science professionals and solar
installations will need to be evaluated to confirm solar potential and things like
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 5
consideration of load bearing roof, worker qualifications and permitting. These reviews
will be conducted by technical experts that are contracted to perform the review or in-
house staff where appropriate. One option is to conduct the technical review as a first
step after eligibility screening, another option is to conduct the technical review only for
projects that have advanced past the Scoring Panel Review. The first option ensures we
weed out projects that have issues before spending resources on a substantive review,
the second option ensures we only spend resources on contractors to conduct reviews
for projects that have been rated strongly enough to be considered. Staff is researching
to further clarify merits of these two options.
• Additional Due Diligence – The purpose and mechanics of due diligence tends to look different
in foundation vs government settings.
Examples and purpose from philanthropic world – In the foundation world, due
o
diligence is the term that is typically used to describe a process of investigating a range
of factors related to the strength of the applicant and proposal. Due diligence review
may include an exploration of things such as the strength of the board and organization,
financial position, DEI commitments, reasonableness of the steps or budget of a
proposed project or program, or veracity of claims regarding named partners. For PCEF,
the draft application and review process has been designed to include as many of these
factors as possible as part of the substantive review. Following this model, additional
due diligence may be conducted as a follow-up when a proposal has passed the Scoring
Panel Review but questions remain and/or verification is needed.
Examples and purpose from government setting – In a government setting due
o
diligence, and the information gained therein, is used primarily to inform grant
requirements and scope. For example, if an application scores well enough to be
recommended for funding but is weak in the area of organizational capacity, that might
indicate a need to get more information about the capacity shortcoming and use that
information to build specific requirements into the grant that would both mitigate risk
associated with these shortcomings and build capacity in those areas within the grantee
organization. Generally, new information about an applicant project collected after the
application period is closed should not be used for scoring since other applicants are not
given the same opportunity to supplement their application.
• Mini-grant process – If committee decides to have an option for mini-grants that support
hosting or attending events, these would have a different review process. For example, these
could be made at staff discretion if criteria are met, there could be a subcommittee that reviews
and decides, or these could be brought to full committee for decision. These could be on a
rolling basis, quarterly, or with other grant cycles.
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback - Use of information gathered in due diligence.
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 6
Decision and Portfolio Balance Process (slide 19)
• Decisions – Full Committee receives a summary for each proposal that includes the review
scores and relevant technical and due diligence information.
Applicants receive a copy of the review packet and are offered the opportunity to
o
provide a short written or video response.
In general, grants are awarded based on highest score, however, deliberation and
o
portfolio balance may impact final awards. Points of deliberation are recorded so that
feedback can be provided to applicant and to demonstrate rationale for any decisions
that depart from awarding grants solely in the order of the highest score. Reasons that
the Committee might depart from highest score need to be clearly defined in the RFP.
This may include applicant response and portfolio balancing. Note that to the extent
feasible, portfolio balancing will primarily be driven by funding bucket and applicant
response. While items such as 20% < frontline serving non-profits, 50% < EE/RE projects
benefit low income and communities of color, and geography will be addressed in
scoring they may also influence portfolio balancing decisions. Portfolio balancing could
occur as a rolling average.
There needs to be a process for contestation/appeal. Staff will work with legal to define.
o
Recommendations go to City Council.
o
• Announcing Grant Awards
List of funded projects, with summaries and total awards, made public.
o
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback - Use of information gathered in due diligence. Reasons for deviating from ranked
recommendations. Discussion is needed regarding applicant response pros/cons, format, impact
and logistics (though not this evening).
Eligibility (slide 20)
Potential eligibility criteria include:
• Eligible non-profit organization. Legislation defines “Non-profit organization” means any
organization recognized by the Internal Revenue Service (“IRS”) under Sections 501 and 521(a)
of the Internal Revenue Code, in addition to other tax-exempt entities recognized by the IRS,
such as schools.”
• Complete. Application is complete.
• Eligible. Proposal is for eligible funding type.
• Budget Parameters. Budget meets any defined restrictions (e.g., funding level min/max).
• GHG. Project will reduce or sequester GHG. For certain funding categories such as workforce
development and training, event mini-grants, planning grants, and capacity grants, GHG
reduction is not expected/measured, though the application will identify how the investment
will support efforts to reduce GHG. Scoring does not happen here; just confirmation that this will
occur.
• Equitable Social Benefit. Project will provide equitable social benefit. Scoring does not happen
here; just confirmation that this will occur.
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 7
• Portland Location. Projects and project beneficiaries must be located in Portland.
• US Manufactured. Solar/renewable technology is primarily US manufactured [legislation; staff
working on definition].
• Wage Requirements. Personnel (Nonprofit staff and employees of contractors and
subcontractors) are budgeted at 180% of minimum wage or more.
• Insurance. Insurance is planned for, in place, or not needed.
• Other items? E.g., out of compliance with IRS filings, labor violations, OSHA violations, liens, etc.
• Temperature: Good to Go, Pretty Close, Some Moderate Revision, Serious Questions or
Reservations.
• Feedback: Anything to add, delete, suggest?
Estimated Review Workload (slides 21 & 22)
When making decisions about who will review applications it is important to consider the amount of
time it will likely take for each review. This will vary by size and type of grant. Overall,
Estimate 2-3 hours per application to receive, screen, communicate to applicant
o
Estimate 2-4 hours per person per application for substantive review (scoring)
o
Estimate 0 to 5 hours per application for due diligence
o
Contracted hours for technical review.
o
To get a rough sense of what this might look like we looked at estimates for a scenario with 45
applications received and a scenario with 100 applications received (See below).
• Temperature: What level of participation in the scoring review panel are you able/willing to
engage in over a two to three-week period?
• None
• Up to 10 hours
• 11 to 20
• 21 to 30
• 31 to 40
• 41 to 80.
Committee Time for Review
• 45 applications
9 committee members each review 5 applications (10-20 hours per person), plus
o
deliberation meeting with other reviewers.
5 committee members each review 9 applications (18-36 hours per person), plus
o
deliberation meeting with other reviewers.
• 100 applications
9 committee members each review 10 applications (20-40 hours per person), plus
o
deliberation meeting with other reviewers.
5 committee members each review 20 applications (40-80 hours per person), plus
o
deliberation meeting with other reviewers.
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 8
Staff Time for Review
• 45 applications
1 staff per application to receive, screen, communicate, manage (2-3 hours): 90-135
o
hours.
2 staff per application for threshold review and scoring panel review (2-4 hours): 180 –
o
360 hours, plus deliberation meeting with other reviewers.
1 staff per application for due diligence (0-2 hours, Yr. 1 assume 2 hours): 90 hours.
o
The estimated staff time to review 45 applications is 360 to 585 hours. Assuming 28
o
hours per week (40-hour work week with 1.5 days per week allocated to other items) it
will take 13 to 21 person weeks to review proposals, requiring 3.25 to 5.25 weeks with
4 staff, 2 to 3 weeks with 7 staff. This does not include time for preparing summaries,
coordinating with committee, managing applicant scoring responses, community input
process, etc.
• 100 applications
1 staff per application, to receive, screen, communicate, manage (2-3 hours) 200-300
o
hours.
2 staff per Scoring Panel Review (2-4 hours) 400-800 hours, plus deliberation meeting
o
with other reviewers.
1 staff per application for due diligence (0-2 hours, Yr. 1 assume 2 hours), 200 hours.
o
The estimated staff time to review 100 applications is 800 to 1,300 hours. Assuming 28
o
hours per week (40-hour work week with 1.5 days per week allocated to other items) it
will take 29 to 46.5 person weeks to review proposals, requiring 7.25 to 11.6 weeks
with 4 staff, 4.1 to 6.6 weeks with 7 staff. This does not include time for preparing
summaries, coordinating with committee, managing applicant scoring responses,
community input process, etc.
Who Reviews (slide 23 & 24)
A few options for who does the reviewing and when.
• Initial Eligibility Screen – suggest staff
• Technical Review – suggest contracted unless in-house expertise
• Threshold Review (as needed) – suggest staff
• Scoring Panel Review – As noted earlier, important to have more than one person scoring a
proposal. Team of reviewers could include a mix of staff, City SMEs (Subject Matter Experts),
Committee members, and/or community volunteers. When deciding who will review proposals
it is important to consider what is a reasonable workload (e.g., amount of time available to
review proposals, orientation and coordination required, and appropriate number of proposal
reviews before quality of review is diminished due to information overload).
PCEF Staff – Anticipate four staff available to conduct reviews year one, possibly up to 7.
o
City SME staff (non-PCEF staff)
o
Committee members – some or all participate in review
o
Community members – discuss pros/cons, how to make workable, idea of “pilot testing”
o
in year one. Reasons to not pilot test include a) staff capacity and timing (extra
coordination required), b) preference for separating the "piloting” of a community
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 9
member review process from “piloting” or launching the grant review process (this is
year one; process should be more fully baked before bringing them in).
• Due Diligence – suggest staff.
• Decision – Committee.
• Considerations: How many Committee members are able and willing to review? How many
application reviews per Committee member? How do we manage various scenarios regarding
the number of applications?
• Recommendation: No community reviewers beyond the Grant Committee in Year 1, with
commitment to implement in future solicitations.
Handout: 3.31.20 Committee Mtg – Draft Grant Review Process pg. 10